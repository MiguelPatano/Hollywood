{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_912e9_row10_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_912e9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_912e9_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_912e9_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_912e9_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_912e9_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_912e9_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_912e9_row1_col1\" class=\"data row1 col1\" >revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_912e9_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_912e9_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_912e9_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_912e9_row3_col1\" class=\"data row3 col1\" >(14160, 33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_912e9_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_912e9_row4_col1\" class=\"data row4 col1\" >(14160, 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_912e9_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_912e9_row5_col1\" class=\"data row5 col1\" >(9912, 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_912e9_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_912e9_row6_col1\" class=\"data row6 col1\" >(4248, 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_912e9_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_912e9_row7_col1\" class=\"data row7 col1\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_912e9_row8_col0\" class=\"data row8 col0\" >Categorical features</td>\n",
       "      <td id=\"T_912e9_row8_col1\" class=\"data row8 col1\" >19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_912e9_row9_col0\" class=\"data row9 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_912e9_row9_col1\" class=\"data row9 col1\" >36.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_912e9_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
       "      <td id=\"T_912e9_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_912e9_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
       "      <td id=\"T_912e9_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_912e9_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_912e9_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_912e9_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_912e9_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_912e9_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_912e9_row14_col1\" class=\"data row14 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_912e9_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n",
       "      <td id=\"T_912e9_row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_912e9_row16_col0\" class=\"data row16 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_912e9_row16_col1\" class=\"data row16 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_912e9_row17_col0\" class=\"data row17 col0\" >Fold Number</td>\n",
       "      <td id=\"T_912e9_row17_col1\" class=\"data row17 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_912e9_row18_col0\" class=\"data row18 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_912e9_row18_col1\" class=\"data row18 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_912e9_row19_col0\" class=\"data row19 col0\" >Use GPU</td>\n",
       "      <td id=\"T_912e9_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_912e9_row20_col0\" class=\"data row20 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_912e9_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_912e9_row21_col0\" class=\"data row21 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_912e9_row21_col1\" class=\"data row21 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_912e9_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_912e9_row22_col0\" class=\"data row22 col0\" >USI</td>\n",
       "      <td id=\"T_912e9_row22_col1\" class=\"data row22 col1\" >5112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x153066595a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b3fd8 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b3fd8_row0_col0, #T_b3fd8_row1_col0, #T_b3fd8_row1_col1, #T_b3fd8_row1_col2, #T_b3fd8_row1_col3, #T_b3fd8_row1_col4, #T_b3fd8_row1_col5, #T_b3fd8_row1_col6, #T_b3fd8_row2_col0, #T_b3fd8_row2_col1, #T_b3fd8_row2_col2, #T_b3fd8_row2_col3, #T_b3fd8_row2_col4, #T_b3fd8_row2_col5, #T_b3fd8_row2_col6, #T_b3fd8_row3_col0, #T_b3fd8_row3_col1, #T_b3fd8_row3_col2, #T_b3fd8_row3_col3, #T_b3fd8_row3_col4, #T_b3fd8_row3_col5, #T_b3fd8_row3_col6, #T_b3fd8_row4_col0, #T_b3fd8_row4_col1, #T_b3fd8_row4_col2, #T_b3fd8_row4_col3, #T_b3fd8_row4_col4, #T_b3fd8_row4_col5, #T_b3fd8_row4_col6, #T_b3fd8_row5_col0, #T_b3fd8_row5_col1, #T_b3fd8_row5_col2, #T_b3fd8_row5_col3, #T_b3fd8_row5_col4, #T_b3fd8_row5_col5, #T_b3fd8_row5_col6, #T_b3fd8_row6_col0, #T_b3fd8_row6_col1, #T_b3fd8_row6_col2, #T_b3fd8_row6_col3, #T_b3fd8_row6_col4, #T_b3fd8_row6_col5, #T_b3fd8_row6_col6, #T_b3fd8_row7_col0, #T_b3fd8_row7_col1, #T_b3fd8_row7_col2, #T_b3fd8_row7_col3, #T_b3fd8_row7_col4, #T_b3fd8_row7_col5, #T_b3fd8_row7_col6, #T_b3fd8_row8_col0, #T_b3fd8_row8_col1, #T_b3fd8_row8_col2, #T_b3fd8_row8_col3, #T_b3fd8_row8_col4, #T_b3fd8_row8_col5, #T_b3fd8_row8_col6, #T_b3fd8_row9_col0, #T_b3fd8_row9_col1, #T_b3fd8_row9_col2, #T_b3fd8_row9_col3, #T_b3fd8_row9_col4, #T_b3fd8_row9_col5, #T_b3fd8_row9_col6, #T_b3fd8_row10_col0, #T_b3fd8_row10_col1, #T_b3fd8_row10_col2, #T_b3fd8_row10_col3, #T_b3fd8_row10_col4, #T_b3fd8_row10_col5, #T_b3fd8_row10_col6, #T_b3fd8_row11_col0, #T_b3fd8_row11_col1, #T_b3fd8_row11_col2, #T_b3fd8_row11_col3, #T_b3fd8_row11_col4, #T_b3fd8_row11_col5, #T_b3fd8_row11_col6, #T_b3fd8_row12_col0, #T_b3fd8_row12_col1, #T_b3fd8_row12_col2, #T_b3fd8_row12_col3, #T_b3fd8_row12_col4, #T_b3fd8_row12_col5, #T_b3fd8_row12_col6, #T_b3fd8_row13_col0, #T_b3fd8_row13_col1, #T_b3fd8_row13_col2, #T_b3fd8_row13_col3, #T_b3fd8_row13_col4, #T_b3fd8_row13_col5, #T_b3fd8_row13_col6, #T_b3fd8_row14_col0, #T_b3fd8_row14_col1, #T_b3fd8_row14_col2, #T_b3fd8_row14_col3, #T_b3fd8_row14_col4, #T_b3fd8_row14_col5, #T_b3fd8_row14_col6, #T_b3fd8_row15_col0, #T_b3fd8_row15_col1, #T_b3fd8_row15_col2, #T_b3fd8_row15_col3, #T_b3fd8_row15_col4, #T_b3fd8_row15_col5, #T_b3fd8_row15_col6, #T_b3fd8_row16_col0, #T_b3fd8_row16_col1, #T_b3fd8_row16_col2, #T_b3fd8_row16_col3, #T_b3fd8_row16_col4, #T_b3fd8_row16_col5, #T_b3fd8_row16_col6, #T_b3fd8_row17_col0, #T_b3fd8_row17_col1, #T_b3fd8_row17_col2, #T_b3fd8_row17_col3, #T_b3fd8_row17_col4, #T_b3fd8_row17_col5, #T_b3fd8_row17_col6, #T_b3fd8_row18_col0, #T_b3fd8_row18_col1, #T_b3fd8_row18_col2, #T_b3fd8_row18_col3, #T_b3fd8_row18_col4, #T_b3fd8_row18_col5, #T_b3fd8_row18_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b3fd8_row0_col1, #T_b3fd8_row0_col2, #T_b3fd8_row0_col3, #T_b3fd8_row0_col4, #T_b3fd8_row0_col5, #T_b3fd8_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_b3fd8_row0_col7, #T_b3fd8_row1_col7, #T_b3fd8_row2_col7, #T_b3fd8_row3_col7, #T_b3fd8_row4_col7, #T_b3fd8_row5_col7, #T_b3fd8_row6_col7, #T_b3fd8_row7_col7, #T_b3fd8_row8_col7, #T_b3fd8_row9_col7, #T_b3fd8_row10_col7, #T_b3fd8_row11_col7, #T_b3fd8_row12_col7, #T_b3fd8_row13_col7, #T_b3fd8_row14_col7, #T_b3fd8_row16_col7, #T_b3fd8_row17_col7, #T_b3fd8_row18_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_b3fd8_row15_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b3fd8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b3fd8_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_b3fd8_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_b3fd8_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_b3fd8_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_b3fd8_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_b3fd8_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_b3fd8_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_b3fd8_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row0\" class=\"row_heading level0 row0\" >knn</th>\n",
       "      <td id=\"T_b3fd8_row0_col0\" class=\"data row0 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_b3fd8_row0_col1\" class=\"data row0 col1\" >44368907.4970</td>\n",
       "      <td id=\"T_b3fd8_row0_col2\" class=\"data row0 col2\" >12705191061732458.0000</td>\n",
       "      <td id=\"T_b3fd8_row0_col3\" class=\"data row0 col3\" >111942605.1038</td>\n",
       "      <td id=\"T_b3fd8_row0_col4\" class=\"data row0 col4\" >0.2318</td>\n",
       "      <td id=\"T_b3fd8_row0_col5\" class=\"data row0 col5\" >8.7135</td>\n",
       "      <td id=\"T_b3fd8_row0_col6\" class=\"data row0 col6\" >27735.8421</td>\n",
       "      <td id=\"T_b3fd8_row0_col7\" class=\"data row0 col7\" >0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row1\" class=\"row_heading level0 row1\" >par</th>\n",
       "      <td id=\"T_b3fd8_row1_col0\" class=\"data row1 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_b3fd8_row1_col1\" class=\"data row1 col1\" >59673668.9345</td>\n",
       "      <td id=\"T_b3fd8_row1_col2\" class=\"data row1 col2\" >14551586715801180.0000</td>\n",
       "      <td id=\"T_b3fd8_row1_col3\" class=\"data row1 col3\" >119938220.7797</td>\n",
       "      <td id=\"T_b3fd8_row1_col4\" class=\"data row1 col4\" >0.1156</td>\n",
       "      <td id=\"T_b3fd8_row1_col5\" class=\"data row1 col5\" >10.2592</td>\n",
       "      <td id=\"T_b3fd8_row1_col6\" class=\"data row1 col6\" >56082.7149</td>\n",
       "      <td id=\"T_b3fd8_row1_col7\" class=\"data row1 col7\" >0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row2\" class=\"row_heading level0 row2\" >lightgbm</th>\n",
       "      <td id=\"T_b3fd8_row2_col0\" class=\"data row2 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_b3fd8_row2_col1\" class=\"data row2 col1\" >61664615.4491</td>\n",
       "      <td id=\"T_b3fd8_row2_col2\" class=\"data row2 col2\" >16267570327870668.0000</td>\n",
       "      <td id=\"T_b3fd8_row2_col3\" class=\"data row2 col3\" >126817454.1054</td>\n",
       "      <td id=\"T_b3fd8_row2_col4\" class=\"data row2 col4\" >0.0121</td>\n",
       "      <td id=\"T_b3fd8_row2_col5\" class=\"data row2 col5\" >10.3471</td>\n",
       "      <td id=\"T_b3fd8_row2_col6\" class=\"data row2 col6\" >63565.6654</td>\n",
       "      <td id=\"T_b3fd8_row2_col7\" class=\"data row2 col7\" >0.5030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row3\" class=\"row_heading level0 row3\" >et</th>\n",
       "      <td id=\"T_b3fd8_row3_col0\" class=\"data row3 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_b3fd8_row3_col1\" class=\"data row3 col1\" >61708522.7135</td>\n",
       "      <td id=\"T_b3fd8_row3_col2\" class=\"data row3 col2\" >16372465419746492.0000</td>\n",
       "      <td id=\"T_b3fd8_row3_col3\" class=\"data row3 col3\" >127266126.3351</td>\n",
       "      <td id=\"T_b3fd8_row3_col4\" class=\"data row3 col4\" >0.0046</td>\n",
       "      <td id=\"T_b3fd8_row3_col5\" class=\"data row3 col5\" >10.3466</td>\n",
       "      <td id=\"T_b3fd8_row3_col6\" class=\"data row3 col6\" >65182.8738</td>\n",
       "      <td id=\"T_b3fd8_row3_col7\" class=\"data row3 col7\" >1.1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row4\" class=\"row_heading level0 row4\" >gbr</th>\n",
       "      <td id=\"T_b3fd8_row4_col0\" class=\"data row4 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_b3fd8_row4_col1\" class=\"data row4 col1\" >61813400.6864</td>\n",
       "      <td id=\"T_b3fd8_row4_col2\" class=\"data row4 col2\" >16403314596648648.0000</td>\n",
       "      <td id=\"T_b3fd8_row4_col3\" class=\"data row4 col3\" >127387028.9763</td>\n",
       "      <td id=\"T_b3fd8_row4_col4\" class=\"data row4 col4\" >0.0026</td>\n",
       "      <td id=\"T_b3fd8_row4_col5\" class=\"data row4 col5\" >10.3493</td>\n",
       "      <td id=\"T_b3fd8_row4_col6\" class=\"data row4 col6\" >65117.5138</td>\n",
       "      <td id=\"T_b3fd8_row4_col7\" class=\"data row4 col7\" >1.2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row5\" class=\"row_heading level0 row5\" >rf</th>\n",
       "      <td id=\"T_b3fd8_row5_col0\" class=\"data row5 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_b3fd8_row5_col1\" class=\"data row5 col1\" >61672916.0577</td>\n",
       "      <td id=\"T_b3fd8_row5_col2\" class=\"data row5 col2\" >16423022751215484.0000</td>\n",
       "      <td id=\"T_b3fd8_row5_col3\" class=\"data row5 col3\" >127458190.5020</td>\n",
       "      <td id=\"T_b3fd8_row5_col4\" class=\"data row5 col4\" >0.0016</td>\n",
       "      <td id=\"T_b3fd8_row5_col5\" class=\"data row5 col5\" >10.3440</td>\n",
       "      <td id=\"T_b3fd8_row5_col6\" class=\"data row5 col6\" >64353.8148</td>\n",
       "      <td id=\"T_b3fd8_row5_col7\" class=\"data row5 col7\" >2.4940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row6\" class=\"row_heading level0 row6\" >xgboost</th>\n",
       "      <td id=\"T_b3fd8_row6_col0\" class=\"data row6 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_b3fd8_row6_col1\" class=\"data row6 col1\" >61964958.8437</td>\n",
       "      <td id=\"T_b3fd8_row6_col2\" class=\"data row6 col2\" >16430565689769610.0000</td>\n",
       "      <td id=\"T_b3fd8_row6_col3\" class=\"data row6 col3\" >127485293.1375</td>\n",
       "      <td id=\"T_b3fd8_row6_col4\" class=\"data row6 col4\" >0.0012</td>\n",
       "      <td id=\"T_b3fd8_row6_col5\" class=\"data row6 col5\" >10.3531</td>\n",
       "      <td id=\"T_b3fd8_row6_col6\" class=\"data row6 col6\" >66349.1758</td>\n",
       "      <td id=\"T_b3fd8_row6_col7\" class=\"data row6 col7\" >0.3840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row7\" class=\"row_heading level0 row7\" >dt</th>\n",
       "      <td id=\"T_b3fd8_row7_col0\" class=\"data row7 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_b3fd8_row7_col1\" class=\"data row7 col1\" >61804040.7947</td>\n",
       "      <td id=\"T_b3fd8_row7_col2\" class=\"data row7 col2\" >16449826706415558.0000</td>\n",
       "      <td id=\"T_b3fd8_row7_col3\" class=\"data row7 col3\" >127558933.5000</td>\n",
       "      <td id=\"T_b3fd8_row7_col4\" class=\"data row7 col4\" >0.0001</td>\n",
       "      <td id=\"T_b3fd8_row7_col5\" class=\"data row7 col5\" >10.3481</td>\n",
       "      <td id=\"T_b3fd8_row7_col6\" class=\"data row7 col6\" >63856.4937</td>\n",
       "      <td id=\"T_b3fd8_row7_col7\" class=\"data row7 col7\" >0.2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row8\" class=\"row_heading level0 row8\" >en</th>\n",
       "      <td id=\"T_b3fd8_row8_col0\" class=\"data row8 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_b3fd8_row8_col1\" class=\"data row8 col1\" >61900595.3817</td>\n",
       "      <td id=\"T_b3fd8_row8_col2\" class=\"data row8 col2\" >16451496872721888.0000</td>\n",
       "      <td id=\"T_b3fd8_row8_col3\" class=\"data row8 col3\" >127568585.6805</td>\n",
       "      <td id=\"T_b3fd8_row8_col4\" class=\"data row8 col4\" >-0.0001</td>\n",
       "      <td id=\"T_b3fd8_row8_col5\" class=\"data row8 col5\" >10.3506</td>\n",
       "      <td id=\"T_b3fd8_row8_col6\" class=\"data row8 col6\" >66307.4057</td>\n",
       "      <td id=\"T_b3fd8_row8_col7\" class=\"data row8 col7\" >0.3820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row9\" class=\"row_heading level0 row9\" >lasso</th>\n",
       "      <td id=\"T_b3fd8_row9_col0\" class=\"data row9 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_b3fd8_row9_col1\" class=\"data row9 col1\" >61897416.5412</td>\n",
       "      <td id=\"T_b3fd8_row9_col2\" class=\"data row9 col2\" >16451381624014282.0000</td>\n",
       "      <td id=\"T_b3fd8_row9_col3\" class=\"data row9 col3\" >127568214.3118</td>\n",
       "      <td id=\"T_b3fd8_row9_col4\" class=\"data row9 col4\" >-0.0001</td>\n",
       "      <td id=\"T_b3fd8_row9_col5\" class=\"data row9 col5\" >10.3503</td>\n",
       "      <td id=\"T_b3fd8_row9_col6\" class=\"data row9 col6\" >66296.7165</td>\n",
       "      <td id=\"T_b3fd8_row9_col7\" class=\"data row9 col7\" >0.5630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row10\" class=\"row_heading level0 row10\" >lar</th>\n",
       "      <td id=\"T_b3fd8_row10_col0\" class=\"data row10 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_b3fd8_row10_col1\" class=\"data row10 col1\" >61971396.8145</td>\n",
       "      <td id=\"T_b3fd8_row10_col2\" class=\"data row10 col2\" >16464397011539300.0000</td>\n",
       "      <td id=\"T_b3fd8_row10_col3\" class=\"data row10 col3\" >127616648.5406</td>\n",
       "      <td id=\"T_b3fd8_row10_col4\" class=\"data row10 col4\" >-0.0008</td>\n",
       "      <td id=\"T_b3fd8_row10_col5\" class=\"data row10 col5\" >10.3536</td>\n",
       "      <td id=\"T_b3fd8_row10_col6\" class=\"data row10 col6\" >66279.3116</td>\n",
       "      <td id=\"T_b3fd8_row10_col7\" class=\"data row10 col7\" >0.2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row11\" class=\"row_heading level0 row11\" >llar</th>\n",
       "      <td id=\"T_b3fd8_row11_col0\" class=\"data row11 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_b3fd8_row11_col1\" class=\"data row11 col1\" >61971396.8143</td>\n",
       "      <td id=\"T_b3fd8_row11_col2\" class=\"data row11 col2\" >16464397011327306.0000</td>\n",
       "      <td id=\"T_b3fd8_row11_col3\" class=\"data row11 col3\" >127616648.5397</td>\n",
       "      <td id=\"T_b3fd8_row11_col4\" class=\"data row11 col4\" >-0.0008</td>\n",
       "      <td id=\"T_b3fd8_row11_col5\" class=\"data row11 col5\" >10.3536</td>\n",
       "      <td id=\"T_b3fd8_row11_col6\" class=\"data row11 col6\" >66279.3116</td>\n",
       "      <td id=\"T_b3fd8_row11_col7\" class=\"data row11 col7\" >0.2630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row12\" class=\"row_heading level0 row12\" >omp</th>\n",
       "      <td id=\"T_b3fd8_row12_col0\" class=\"data row12 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_b3fd8_row12_col1\" class=\"data row12 col1\" >61971396.8143</td>\n",
       "      <td id=\"T_b3fd8_row12_col2\" class=\"data row12 col2\" >16464397011327284.0000</td>\n",
       "      <td id=\"T_b3fd8_row12_col3\" class=\"data row12 col3\" >127616648.5397</td>\n",
       "      <td id=\"T_b3fd8_row12_col4\" class=\"data row12 col4\" >-0.0008</td>\n",
       "      <td id=\"T_b3fd8_row12_col5\" class=\"data row12 col5\" >10.3536</td>\n",
       "      <td id=\"T_b3fd8_row12_col6\" class=\"data row12 col6\" >66279.3116</td>\n",
       "      <td id=\"T_b3fd8_row12_col7\" class=\"data row12 col7\" >0.2650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row13\" class=\"row_heading level0 row13\" >lr</th>\n",
       "      <td id=\"T_b3fd8_row13_col0\" class=\"data row13 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_b3fd8_row13_col1\" class=\"data row13 col1\" >61971396.8143</td>\n",
       "      <td id=\"T_b3fd8_row13_col2\" class=\"data row13 col2\" >16464397011327298.0000</td>\n",
       "      <td id=\"T_b3fd8_row13_col3\" class=\"data row13 col3\" >127616648.5397</td>\n",
       "      <td id=\"T_b3fd8_row13_col4\" class=\"data row13 col4\" >-0.0008</td>\n",
       "      <td id=\"T_b3fd8_row13_col5\" class=\"data row13 col5\" >10.3536</td>\n",
       "      <td id=\"T_b3fd8_row13_col6\" class=\"data row13 col6\" >66279.3116</td>\n",
       "      <td id=\"T_b3fd8_row13_col7\" class=\"data row13 col7\" >0.8010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row14\" class=\"row_heading level0 row14\" >ridge</th>\n",
       "      <td id=\"T_b3fd8_row14_col0\" class=\"data row14 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_b3fd8_row14_col1\" class=\"data row14 col1\" >61971396.8143</td>\n",
       "      <td id=\"T_b3fd8_row14_col2\" class=\"data row14 col2\" >16464397011327290.0000</td>\n",
       "      <td id=\"T_b3fd8_row14_col3\" class=\"data row14 col3\" >127616648.5397</td>\n",
       "      <td id=\"T_b3fd8_row14_col4\" class=\"data row14 col4\" >-0.0008</td>\n",
       "      <td id=\"T_b3fd8_row14_col5\" class=\"data row14 col5\" >10.3536</td>\n",
       "      <td id=\"T_b3fd8_row14_col6\" class=\"data row14 col6\" >66279.3116</td>\n",
       "      <td id=\"T_b3fd8_row14_col7\" class=\"data row14 col7\" >0.2580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row15\" class=\"row_heading level0 row15\" >dummy</th>\n",
       "      <td id=\"T_b3fd8_row15_col0\" class=\"data row15 col0\" >Dummy Regressor</td>\n",
       "      <td id=\"T_b3fd8_row15_col1\" class=\"data row15 col1\" >61971396.8143</td>\n",
       "      <td id=\"T_b3fd8_row15_col2\" class=\"data row15 col2\" >16464397011327264.0000</td>\n",
       "      <td id=\"T_b3fd8_row15_col3\" class=\"data row15 col3\" >127616648.5397</td>\n",
       "      <td id=\"T_b3fd8_row15_col4\" class=\"data row15 col4\" >-0.0008</td>\n",
       "      <td id=\"T_b3fd8_row15_col5\" class=\"data row15 col5\" >10.3536</td>\n",
       "      <td id=\"T_b3fd8_row15_col6\" class=\"data row15 col6\" >66279.3116</td>\n",
       "      <td id=\"T_b3fd8_row15_col7\" class=\"data row15 col7\" >0.2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row16\" class=\"row_heading level0 row16\" >ada</th>\n",
       "      <td id=\"T_b3fd8_row16_col0\" class=\"data row16 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_b3fd8_row16_col1\" class=\"data row16 col1\" >52984919.0975</td>\n",
       "      <td id=\"T_b3fd8_row16_col2\" class=\"data row16 col2\" >16686792710586790.0000</td>\n",
       "      <td id=\"T_b3fd8_row16_col3\" class=\"data row16 col3\" >128481927.8164</td>\n",
       "      <td id=\"T_b3fd8_row16_col4\" class=\"data row16 col4\" >-0.0146</td>\n",
       "      <td id=\"T_b3fd8_row16_col5\" class=\"data row16 col5\" >10.0539</td>\n",
       "      <td id=\"T_b3fd8_row16_col6\" class=\"data row16 col6\" >42053.6701</td>\n",
       "      <td id=\"T_b3fd8_row16_col7\" class=\"data row16 col7\" >0.6530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row17\" class=\"row_heading level0 row17\" >huber</th>\n",
       "      <td id=\"T_b3fd8_row17_col0\" class=\"data row17 col0\" >Huber Regressor</td>\n",
       "      <td id=\"T_b3fd8_row17_col1\" class=\"data row17 col1\" >64377318.3024</td>\n",
       "      <td id=\"T_b3fd8_row17_col2\" class=\"data row17 col2\" >17041352202624758.0000</td>\n",
       "      <td id=\"T_b3fd8_row17_col3\" class=\"data row17 col3\" >129938664.8539</td>\n",
       "      <td id=\"T_b3fd8_row17_col4\" class=\"data row17 col4\" >-0.0395</td>\n",
       "      <td id=\"T_b3fd8_row17_col5\" class=\"data row17 col5\" >10.3587</td>\n",
       "      <td id=\"T_b3fd8_row17_col6\" class=\"data row17 col6\" >63278.6336</td>\n",
       "      <td id=\"T_b3fd8_row17_col7\" class=\"data row17 col7\" >0.3580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3fd8_level0_row18\" class=\"row_heading level0 row18\" >br</th>\n",
       "      <td id=\"T_b3fd8_row18_col0\" class=\"data row18 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_b3fd8_row18_col1\" class=\"data row18 col1\" >73437048.9650</td>\n",
       "      <td id=\"T_b3fd8_row18_col2\" class=\"data row18 col2\" >23469162861732820.0000</td>\n",
       "      <td id=\"T_b3fd8_row18_col3\" class=\"data row18 col3\" >145481459.2095</td>\n",
       "      <td id=\"T_b3fd8_row18_col4\" class=\"data row18 col4\" >-0.4098</td>\n",
       "      <td id=\"T_b3fd8_row18_col5\" class=\"data row18 col5\" >10.3781</td>\n",
       "      <td id=\"T_b3fd8_row18_col6\" class=\"data row18 col6\" >84189.1334</td>\n",
       "      <td id=\"T_b3fd8_row18_col7\" class=\"data row18 col7\" >0.2770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15306659780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#VAMOS A VER QUE HACE Pycaret\n",
    "#Al querer predecir un número vamos a usar regression en lugar de clasiification que es para predecir categorías\n",
    "\n",
    "from pycaret.regression import *\n",
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv('movies_Final.csv')\n",
    "\n",
    "# Inicializar el entorno de PyCaret\n",
    "\n",
    "exp_reg101 = setup(data=movies, target='revenue', session_id=123)\n",
    "\n",
    "# Comparar varios modelos de regresión\n",
    "best = compare_models()\n",
    "\n",
    "#El resultado mandando el ds es que el mejor modelo es K Neighbors Regressor\n",
    "#voy a lanzarlo otra vez pero con los campos vectorizados\n",
    "\n",
    "# Convertir la columna release_date a datetime\n",
    "movies['release_date'] = pd.to_datetime(movies['release_date'], errors='coerce')\n",
    "\n",
    "# Rellenar los valores nulos en las columnas importantes\n",
    "movies['actors'] = movies['actors'].fillna('')\n",
    "movies['directors_name'] = movies['directors_name'].fillna('')\n",
    "movies['production_companies'] = movies['production_companies'].fillna('')\n",
    "movies['genres'] = movies['genres'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pycaret\n",
    "pycaret.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mfrod\\Downloads\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas pruebas, ahora voy a sumar las peliculas futuras al proceso, primero con RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio: 1.0305985612586204e+16\n",
      "                                           title    real_revenue  \\\n",
      "15                             Avengers: Endgame  $2,800,000,000   \n",
      "248               Jurassic World: Fallen Kingdom  $1,310,466,296   \n",
      "99                                        Frozen  $1,274,219,009   \n",
      "113                               Captain Marvel  $1,131,416,446   \n",
      "428              Transformers: Age of Extinction  $1,104,054,072   \n",
      "330             Star Wars: The Rise of Skywalker  $1,074,144,248   \n",
      "149  Pirates of the Caribbean: On Stranger Tides  $1,045,713,802   \n",
      "538                              Despicable Me 3  $1,031,552,585   \n",
      "101                                     Zootopia  $1,023,784,195   \n",
      "59        Harry Potter and the Half-Blood Prince    $933,959,197   \n",
      "\n",
      "    predicted_revenue  \n",
      "15     $1,423,398,897  \n",
      "248      $421,396,816  \n",
      "99       $397,792,559  \n",
      "113      $598,469,067  \n",
      "428      $308,350,356  \n",
      "330      $938,612,287  \n",
      "149      $340,274,247  \n",
      "538      $222,670,028  \n",
      "101      $115,963,532  \n",
      "59       $472,876,284  \n",
      "                                            title predicted_revenue\n",
      "42  Mission: Impossible - Dead Reckoning Part Two      $445,392,683\n",
      "4                                            Elio      $314,442,693\n",
      "31                                        Moana 2      $293,862,403\n",
      "5                                    Inside Out 2      $264,073,381\n",
      "73                                       Twisters      $253,591,545\n",
      "51                                       Avatar 5      $192,230,644\n",
      "48                                       Avatar 3      $182,836,912\n",
      "44                                Despicable Me 4      $170,804,341\n",
      "14                            Joker: Folie à Deux      $163,471,416\n",
      "49                                       Avatar 4      $160,174,188\n"
     ]
    }
   ],
   "source": [
    "#######Este es el modelo que más me gusta: RandomForestRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import hstack\n",
    "import joblib\n",
    "\n",
    "# Cargar los datos\n",
    "movies = pd.read_csv('movies_Final.csv')\n",
    "futuras = pd.read_csv('dataset_futuras.csv')\n",
    "\n",
    "# Convertir la columna release_date a datetime\n",
    "movies['release_date'] = pd.to_datetime(movies['release_date'], errors='coerce')\n",
    "futuras['release_date'] = pd.to_datetime(futuras['release_date'], errors='coerce')\n",
    "\n",
    "# Rellenar los valores nulos en las columnas importantes\n",
    "movies['actors'] = movies['actors'].fillna('')\n",
    "movies['directors_name'] = movies['directors_name'].fillna('')\n",
    "movies['production_companies'] = movies['production_companies'].fillna('')\n",
    "movies['genres'] = movies['genres'].fillna('')\n",
    "futuras['actors'] = futuras['actors'].fillna('')\n",
    "futuras['directors_name'] = futuras['directors_name'].fillna('')\n",
    "futuras['production_companies'] = futuras['production_companies'].fillna('')\n",
    "futuras['genres'] = futuras['genres'].fillna('')\n",
    "\n",
    "# Vectorizar las características textuales\n",
    "all_actors = pd.concat([movies['actors'], futuras['actors']])\n",
    "all_directors = pd.concat([movies['directors_name'], futuras['directors_name']])\n",
    "all_companies = pd.concat([movies['production_companies'], futuras['production_companies']])\n",
    "all_genres = pd.concat([movies['genres'], futuras['genres']])\n",
    "\n",
    "# Entrenar vectorizadores\n",
    "vectorizer_actors = CountVectorizer()\n",
    "vectorizer_actors.fit(all_actors)\n",
    "\n",
    "vectorizer_directors = CountVectorizer()\n",
    "vectorizer_directors.fit(all_directors)\n",
    "\n",
    "vectorizer_companies = CountVectorizer()\n",
    "vectorizer_companies.fit(all_companies)\n",
    "\n",
    "vectorizer_genres = CountVectorizer()\n",
    "vectorizer_genres.fit(all_genres)\n",
    "\n",
    "# Transformar datos de películas estrenadas\n",
    "actors_matrix = vectorizer_actors.transform(movies['actors'])\n",
    "directors_matrix = vectorizer_directors.transform(movies['directors_name'])\n",
    "companies_matrix = vectorizer_companies.transform(movies['production_companies'])\n",
    "genres_matrix = vectorizer_genres.transform(movies['genres'])\n",
    "\n",
    "# Transformar datos de futuras películas\n",
    "actors_matrix_futuras = vectorizer_actors.transform(futuras['actors'])\n",
    "directors_matrix_futuras = vectorizer_directors.transform(futuras['directors_name'])\n",
    "companies_matrix_futuras = vectorizer_companies.transform(futuras['production_companies'])\n",
    "genres_matrix_futuras = vectorizer_genres.transform(futuras['genres'])\n",
    "\n",
    "# Concatenar todas las características\n",
    "X = hstack([actors_matrix, directors_matrix, companies_matrix, genres_matrix])\n",
    "\n",
    "# Estandarizar características numéricas\n",
    "scaler = StandardScaler(with_mean=False)  \n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Guardar los vectorizadores y el escalador\n",
    "joblib.dump(vectorizer_actors, 'vectorizer_actors.pkl')\n",
    "joblib.dump(vectorizer_directors, 'vectorizer_directors.pkl')\n",
    "joblib.dump(vectorizer_companies, 'vectorizer_companies.pkl')\n",
    "joblib.dump(vectorizer_genres, 'vectorizer_genres.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Variable objetivo\n",
    "y = np.log1p(movies['revenue'])\n",
    "\n",
    "# dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Guardar el modelo\n",
    "joblib.dump(model, 'revenue_predictor.pkl')\n",
    "\n",
    "# Predecir y evaluar el modelo\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)  # Transformación inversa del logaritmo\n",
    "y_test_original = np.expm1(y_test)  # Transformación inversa del logaritmo\n",
    "\n",
    "mse = mean_squared_error(y_test_original, y_pred)\n",
    "print(f'Error cuadrático medio: {mse}')\n",
    "\n",
    "# Seleccionar las 10 películas con el revenue más alto del conjunto de prueba\n",
    "top_10_indices = y_test_original.nlargest(10).index\n",
    "top_10_movies = movies.loc[top_10_indices]\n",
    "top_10_real_revenue = y_test_original.loc[top_10_indices]\n",
    "top_10_predicted_revenue = pd.Series(y_pred, index=y_test.index).loc[top_10_indices]\n",
    "\n",
    "# Crear un DataFrame con los resultados y formatear los valores\n",
    "result_df = pd.DataFrame({\n",
    "    'title': top_10_movies['title'].values,\n",
    "    'real_revenue': top_10_real_revenue.apply(lambda x: f\"${x:,.0f}\"),\n",
    "    'predicted_revenue': top_10_predicted_revenue.apply(lambda x: f\"${x:,.0f}\")\n",
    "})\n",
    "\n",
    "print(result_df)\n",
    "\n",
    "# Ahora aplicamos el modelo sobre las futuras películas\n",
    "# Transformar y escalar las características usando los objetos cargados\n",
    "X_futuras = hstack([actors_matrix_futuras, directors_matrix_futuras, companies_matrix_futuras, genres_matrix_futuras])\n",
    "X_futuras = scaler.transform(X_futuras)\n",
    "\n",
    "# Predecir con el modelo entrenado\n",
    "y_futuras_pred_log = model.predict(X_futuras)\n",
    "y_futuras_pred = np.expm1(y_futuras_pred_log)\n",
    "\n",
    "futuras['predicted_revenue'] = y_futuras_pred\n",
    "\n",
    "# Seleccionar las 10 películas con la predicción de revenue más alto\n",
    "top_10_futuras = futuras.nlargest(10, 'predicted_revenue').copy()\n",
    "\n",
    "# Formatear los valores de predicción de revenue\n",
    "top_10_futuras['predicted_revenue'] = top_10_futuras['predicted_revenue'].apply(lambda x: f\"${x:,.0f}\")\n",
    "\n",
    "print(top_10_futuras[['title', 'predicted_revenue']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>status</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>...</th>\n",
       "      <th>año</th>\n",
       "      <th>era</th>\n",
       "      <th>decade</th>\n",
       "      <th>title_es</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>actors</th>\n",
       "      <th>directors_name</th>\n",
       "      <th>produced_in_USA_or_UK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975056</td>\n",
       "      <td>Cabrini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>In Production</td>\n",
       "      <td>2024-03-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/os4UQLyj0GkqarDwPY73qSzgNhY.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Era del Cine Contemporáneo y la Globalización</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Cabrini</td>\n",
       "      <td>142.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4176.0</td>\n",
       "      <td>Giancarlo Giannini, John Lithgow, David Morse,...</td>\n",
       "      <td>Alejandro Monteverde</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>974036</td>\n",
       "      <td>Ordinary Angels</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Post Production</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>False</td>\n",
       "      <td>/wrzHQXtcnunPjrbfwlPLIr2TRRC.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Era del Cine Contemporáneo y la Globalización</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Ordinary Angels</td>\n",
       "      <td>118.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4894.0</td>\n",
       "      <td>Nancy Travis, Hilary Swank, Tamala Jones, Drew...</td>\n",
       "      <td>Jon Gunn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986056</td>\n",
       "      <td>Thunderbolts</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Planned</td>\n",
       "      <td>2024-12-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/vzVojqW0zF9QrXVGuj8PwhxWACD.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Era del Cine Contemporáneo y la Globalización</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Thunderbolts</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Julia Louis-Dreyfus, Rachel Weisz, David Harbo...</td>\n",
       "      <td>Jake Schreier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1262868</td>\n",
       "      <td>Woodbridge</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Post Production</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Era del Cine Contemporáneo y la Globalización</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Woodbridge</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sophi Knight, Carrington Bornstein, Julia Mast...</td>\n",
       "      <td>Stephen Meier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1022787</td>\n",
       "      <td>Elio</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>In Production</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>/oLN4E0pX0z0wLnlfyn8vwnuGBYF.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Era del Cine Contemporáneo y la Globalización</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Elío</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brad Garrett, America Ferrera, Yonas Kibreab, ...</td>\n",
       "      <td>Adrian Molina</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            title  vote_average  vote_count           status  \\\n",
       "0   975056          Cabrini           0.0           0    In Production   \n",
       "1   974036  Ordinary Angels           0.0           0  Post Production   \n",
       "2   986056     Thunderbolts           0.0           0          Planned   \n",
       "3  1262868       Woodbridge           0.0           0  Post Production   \n",
       "4  1022787             Elio           0.0           0    In Production   \n",
       "\n",
       "  release_date  revenue  runtime  adult                     backdrop_path  \\\n",
       "0   2024-03-08        0        0  False  /os4UQLyj0GkqarDwPY73qSzgNhY.jpg   \n",
       "1   2024-02-23        0      116  False  /wrzHQXtcnunPjrbfwlPLIr2TRRC.jpg   \n",
       "2   2024-12-18        0        0  False  /vzVojqW0zF9QrXVGuj8PwhxWACD.jpg   \n",
       "3   2024-04-01        0       85  False                               NaN   \n",
       "4   2024-02-28        0       90  False  /oLN4E0pX0z0wLnlfyn8vwnuGBYF.jpg   \n",
       "\n",
       "   ...   año                                            era  decade  \\\n",
       "0  ...  2024  Era del Cine Contemporáneo y la Globalización  2020.0   \n",
       "1  ...  2024  Era del Cine Contemporáneo y la Globalización  2020.0   \n",
       "2  ...  2024  Era del Cine Contemporáneo y la Globalización  2020.0   \n",
       "3  ...  2024  Era del Cine Contemporáneo y la Globalización  2020.0   \n",
       "4  ...  2024  Era del Cine Contemporáneo y la Globalización  2020.0   \n",
       "\n",
       "          title_es runtimeMinutes averageRating  numVotes  \\\n",
       "0          Cabrini          142.0           7.7    4176.0   \n",
       "1  Ordinary Angels          118.0           7.4    4894.0   \n",
       "2     Thunderbolts            0.0           NaN       NaN   \n",
       "3       Woodbridge           85.0           NaN       NaN   \n",
       "4             Elío            0.0           NaN       NaN   \n",
       "\n",
       "                                              actors        directors_name  \\\n",
       "0  Giancarlo Giannini, John Lithgow, David Morse,...  Alejandro Monteverde   \n",
       "1  Nancy Travis, Hilary Swank, Tamala Jones, Drew...              Jon Gunn   \n",
       "2  Julia Louis-Dreyfus, Rachel Weisz, David Harbo...         Jake Schreier   \n",
       "3  Sophi Knight, Carrington Bornstein, Julia Mast...         Stephen Meier   \n",
       "4  Brad Garrett, America Ferrera, Yonas Kibreab, ...         Adrian Molina   \n",
       "\n",
       "  produced_in_USA_or_UK  \n",
       "0                  True  \n",
       "1                  True  \n",
       "2                  True  \n",
       "3                  True  \n",
       "4                  True  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futuras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14160 entries, 0 to 14159\n",
      "Data columns (total 34 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     14160 non-null  int64  \n",
      " 1   title                  14160 non-null  object \n",
      " 2   vote_average           14160 non-null  float64\n",
      " 3   vote_count             14160 non-null  int64  \n",
      " 4   status                 14160 non-null  object \n",
      " 5   release_date           14160 non-null  object \n",
      " 6   revenue                14160 non-null  int64  \n",
      " 7   runtime                14160 non-null  int64  \n",
      " 8   adult                  14160 non-null  bool   \n",
      " 9   budget                 14160 non-null  int64  \n",
      " 10  imdb_id                14160 non-null  object \n",
      " 11  original_language      14160 non-null  object \n",
      " 12  original_title         14160 non-null  object \n",
      " 13  overview               14160 non-null  object \n",
      " 14  popularity             14160 non-null  float64\n",
      " 15  poster_path            14160 non-null  object \n",
      " 16  tagline                14160 non-null  object \n",
      " 17  genres                 14160 non-null  object \n",
      " 18  production_companies   14160 non-null  object \n",
      " 19  production_countries   14160 non-null  object \n",
      " 20  spoken_languages       14160 non-null  object \n",
      " 21  keywords               14160 non-null  object \n",
      " 22  año                    14160 non-null  int64  \n",
      " 23  era                    14160 non-null  object \n",
      " 24  decade                 14160 non-null  float64\n",
      " 25  produced_in_USA_or_UK  14160 non-null  bool   \n",
      " 26  genre_0                14160 non-null  object \n",
      " 27  runtime_level          14160 non-null  int64  \n",
      " 28  title_es               14160 non-null  object \n",
      " 29  actors                 14160 non-null  object \n",
      " 30  directors_name         14160 non-null  object \n",
      " 31  averageRating          14160 non-null  object \n",
      " 32  numVotes               14160 non-null  object \n",
      " 33  weightedRating         14160 non-null  object \n",
      "dtypes: bool(2), float64(3), int64(7), object(22)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mpata_lrc8dz0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mpata_lrc8dz0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score del modelo en el conjunto de prueba: -0.09476202456925598\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Descargar los recursos necesarios de NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Cargar los DataFrames\n",
    "movies = pd.read_csv('movies_Final.csv')\n",
    "futuras = pd.read_csv('dataset_futuras.csv')\n",
    "\n",
    "# Función para preprocesar texto\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Combinar las columnas de texto en una sola columna\n",
    "def combine_text_columns(df):\n",
    "    df['combined_text'] = df['actors'] + ' ' + df['directors_name'] + ' ' + df['keywords'] + ' ' + df['production_companies'] + ' ' + df['genres']\n",
    "    df['combined_text'] = df['combined_text'].apply(preprocess_text)\n",
    "    return df\n",
    "\n",
    "movies = combine_text_columns(movies)\n",
    "futuras = combine_text_columns(futuras)\n",
    "\n",
    "# Rellenar valores nulos\n",
    "movies.fillna('', inplace=True)\n",
    "futuras.fillna('', inplace=True)\n",
    "\n",
    "# Inicializar el vectorizador TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Ajustar y transformar los datos de entrenamiento\n",
    "X = tfidf.fit_transform(movies['combined_text'])\n",
    "\n",
    "# Transformar los datos futuros\n",
    "X_futuras = tfidf.transform(futuras['combined_text'])\n",
    "\n",
    "# Variable objetivo (y) y características (X)\n",
    "y = movies['revenue']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar y entrenar el modelo\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(f\"Score del modelo en el conjunto de prueba: {model.score(X_test, y_test)}\")\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model.predict(X_futuras)\n",
    "\n",
    "# Añadir las predicciones al DataFrame de futuras películas\n",
    "futuras['predicted_revenue'] = predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Despues de ver los resultados nos quedamos con este modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Películas Futuras con Mayores Ingresos Estimados:\n",
      "                               title  predicted_revenue\n",
      "51                          Avatar 5      1060246840.50\n",
      "49                          Avatar 4      1047534551.64\n",
      "48                          Avatar 3      1034375639.43\n",
      "68                             Blade      1020470549.75\n",
      "5                       Inside Out 2       953916505.01\n",
      "44                   Despicable Me 4       827037169.88\n",
      "45                        Deadpool 3       790607084.57\n",
      "2                       Thunderbolts       703165770.45\n",
      "40                        Snow White       574682570.01\n",
      "31                           Moana 2       554636509.13\n",
      "14               Joker: Folie à Deux       476801946.89\n",
      "61  Captain America: Brave New World       467173245.56\n",
      "73                          Twisters       406700736.61\n",
      "76                    Dune: Part Two       400701458.57\n",
      "23              Sonic the Hedgehog 3       387865713.27\n",
      "\n",
      "Top 15 Películas Estrenadas con Mayores Ingresos Reales:\n",
      "                            title     revenue\n",
      "3                          avatar  2923706026\n",
      "15              avengers: endgame  2800000000\n",
      "275      avatar: the way of water  2320250281\n",
      "17                        titanic  2264162353\n",
      "56   star wars: the force awakens  2068223624\n",
      "6          avengers: infinity war  2052415039\n",
      "57        spider-man: no way home  1921847111\n",
      "44                 jurassic world  1671537444\n",
      "310                 the lion king  1663075401\n",
      "4                    the avengers  1518815515\n",
      "264                     furious 7  1515341399\n",
      "433             top gun: maverick  1488732821\n",
      "329                     frozen ii  1450026933\n",
      "803                        barbie  1428545028\n",
      "23        avengers: age of ultron  1405403694\n"
     ]
    }
   ],
   "source": [
    "# Ordenar por los ingresos previstos y seleccionar las 15 principales\n",
    "top_15_movies_futuras = futuras.nlargest(15, 'predicted_revenue')\n",
    "\n",
    "# Ajustar la visualización para evitar la notación científica\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Mostrar las 15 películas futuras con mayores ingresos estimados\n",
    "print(\"Top 15 Películas Futuras con Mayores Ingresos Estimados:\")\n",
    "print(top_15_movies_futuras[['title', 'predicted_revenue']])\n",
    "\n",
    "# Ordenar las películas ya estrenadas por ingresos reales y seleccionar las 15 principales\n",
    "top_15_movies_actuales = movies.nlargest(15, 'revenue')\n",
    "\n",
    "# Mostrar las 15 películas ya estrenadas con mayores ingresos reales\n",
    "print(\"\\nTop 15 Películas Estrenadas con Mayores Ingresos Reales:\")\n",
    "print(top_15_movies_actuales[['title', 'revenue']])\n",
    "#vamos a exportar top_15_movies_futuras a un csv\n",
    "top_15_movies_futuras.to_csv('top_15_movies_futuras.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            title predicted_revenue\n",
      "42  Mission: Impossible - Dead Reckoning Part Two      $445,392,683\n",
      "4                                            Elio      $314,442,693\n",
      "31                                        Moana 2      $293,862,403\n",
      "5                                    Inside Out 2      $264,073,381\n",
      "73                                       Twisters      $253,591,545\n",
      "51                                       Avatar 5      $192,230,644\n",
      "48                                       Avatar 3      $182,836,912\n",
      "44                                Despicable Me 4      $170,804,341\n",
      "14                            Joker: Folie à Deux      $163,471,416\n",
      "49                                       Avatar 4      $160,174,188\n"
     ]
    }
   ],
   "source": [
    "#Si solo quiero usar el modelo entrenado puedo usar esta parte del código:\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Cargar los datos\n",
    "futuras = pd.read_csv('dataset_futuras.csv')\n",
    "\n",
    "# Convertir la columna release_date a datetime\n",
    "futuras['release_date'] = pd.to_datetime(futuras['release_date'], errors='coerce')\n",
    "\n",
    "# Rellenar los valores nulos en las columnas importantes\n",
    "futuras['actors'] = futuras['actors'].fillna('')\n",
    "futuras['directors_name'] = futuras['directors_name'].fillna('')\n",
    "futuras['production_companies'] = futuras['production_companies'].fillna('')\n",
    "futuras['genres'] = futuras['genres'].fillna('')\n",
    "\n",
    "# Cargar los vectorizadores y el escalador\n",
    "vectorizer_actors = joblib.load('vectorizer_actors.pkl')\n",
    "vectorizer_directors = joblib.load('vectorizer_directors.pkl')\n",
    "vectorizer_companies = joblib.load('vectorizer_companies.pkl')\n",
    "vectorizer_genres = joblib.load('vectorizer_genres.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "model = joblib.load('revenue_predictor.pkl')\n",
    "\n",
    "# Transformar datos de futuras películas\n",
    "actors_matrix_futuras = vectorizer_actors.transform(futuras['actors'])\n",
    "directors_matrix_futuras = vectorizer_directors.transform(futuras['directors_name'])\n",
    "companies_matrix_futuras = vectorizer_companies.transform(futuras['production_companies'])\n",
    "genres_matrix_futuras = vectorizer_genres.transform(futuras['genres'])\n",
    "\n",
    "# Concatenar todas las características y escalar\n",
    "X_futuras = hstack([actors_matrix_futuras, directors_matrix_futuras, companies_matrix_futuras, genres_matrix_futuras])\n",
    "X_futuras = scaler.transform(X_futuras)\n",
    "\n",
    "# Predecir con el modelo cargado\n",
    "y_futuras_pred_log = model.predict(X_futuras)\n",
    "y_futuras_pred = np.expm1(y_futuras_pred_log)\n",
    "\n",
    "futuras['predicted_revenue'] = y_futuras_pred\n",
    "\n",
    "# Seleccionar las 10 películas con la predicción de revenue más alto\n",
    "top_10_futuras = futuras.nlargest(10, 'predicted_revenue').copy()\n",
    "\n",
    "# Formatear los valores de predicción de revenue\n",
    "top_10_futuras['predicted_revenue'] = top_10_futuras['predicted_revenue'].apply(lambda x: f\"${x:,.0f}\")\n",
    "\n",
    "print(top_10_futuras[['title', 'predicted_revenue']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a usar el modelo que nos recomienda Pycaret KNN\n",
    "Los resultados como títulos de peliculas suenan coerentes pero la variable objetivo queda mucho más alejada de la realidad que el anterior modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento (KNeighborsRegressor): 12.547938585281372 segundos\n",
      "Error cuadrático medio (KNeighborsRegressor): 1.942748963027762e+16\n",
      "Tiempo de entrenamiento (GradientBoostingRegressor): 138.80754685401917 segundos\n",
      "Error cuadrático medio (GradientBoostingRegressor): 6.876916331488677e+16\n",
      "                                           title    real_revenue  \\\n",
      "15                             Avengers: Endgame  $2,800,000,000   \n",
      "248               Jurassic World: Fallen Kingdom  $1,310,466,296   \n",
      "99                                        Frozen  $1,274,219,009   \n",
      "113                               Captain Marvel  $1,131,416,446   \n",
      "428              Transformers: Age of Extinction  $1,104,054,072   \n",
      "330             Star Wars: The Rise of Skywalker  $1,074,144,248   \n",
      "149  Pirates of the Caribbean: On Stranger Tides  $1,045,713,802   \n",
      "538                              Despicable Me 3  $1,031,552,585   \n",
      "101                                     Zootopia  $1,023,784,195   \n",
      "59        Harry Potter and the Half-Blood Prince    $933,959,197   \n",
      "\n",
      "    predicted_revenue  \n",
      "15         $1,737,095  \n",
      "248        $6,870,690  \n",
      "99        $55,558,417  \n",
      "113        $1,737,095  \n",
      "428        $9,722,092  \n",
      "330          $110,516  \n",
      "149       $22,813,372  \n",
      "538       $52,026,344  \n",
      "101      $104,076,854  \n",
      "59         $5,818,644  \n",
      "                                             title predicted_revenue\n",
      "59  The Lord of the Rings: The War of the Rohirrim      $226,812,708\n",
      "31                                         Moana 2      $206,270,869\n",
      "73                                        Twisters      $128,210,478\n",
      "4                                             Elio       $78,553,274\n",
      "55                                        Garfield       $40,089,518\n",
      "44                                 Despicable Me 4       $31,900,515\n",
      "70                                Transformers One       $22,696,972\n",
      "64                                      Madame Web       $21,978,303\n",
      "47                                       Ballerina       $19,635,208\n",
      "56                                    The Fall Guy       $15,651,446\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import hstack\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# Cargar los datos\n",
    "movies = pd.read_csv('movies_Final.csv')\n",
    "futuras = pd.read_csv('dataset_futuras.csv')\n",
    "\n",
    "# Convertir la columna release_date a datetime\n",
    "movies['release_date'] = pd.to_datetime(movies['release_date'], errors='coerce')\n",
    "futuras['release_date'] = pd.to_datetime(futuras['release_date'], errors='coerce')\n",
    "\n",
    "# Rellenar los valores nulos en las columnas importantes\n",
    "movies['actors'] = movies['actors'].fillna('')\n",
    "movies['directors_name'] = movies['directors_name'].fillna('')\n",
    "movies['production_companies'] = movies['production_companies'].fillna('')\n",
    "movies['genres'] = movies['genres'].fillna('')\n",
    "futuras['actors'] = futuras['actors'].fillna('')\n",
    "futuras['directors_name'] = futuras['directors_name'].fillna('')\n",
    "futuras['production_companies'] = futuras['production_companies'].fillna('')\n",
    "futuras['genres'] = futuras['genres'].fillna('')\n",
    "\n",
    "# Vectorizar las características textuales\n",
    "all_actors = pd.concat([movies['actors'], futuras['actors']])\n",
    "all_directors = pd.concat([movies['directors_name'], futuras['directors_name']])\n",
    "all_companies = pd.concat([movies['production_companies'], futuras['production_companies']])\n",
    "all_genres = pd.concat([movies['genres'], futuras['genres']])\n",
    "\n",
    "# Entrenar vectorizadores\n",
    "vectorizer_actors = CountVectorizer()\n",
    "vectorizer_actors.fit(all_actors)\n",
    "\n",
    "vectorizer_directors = CountVectorizer()\n",
    "vectorizer_directors.fit(all_directors)\n",
    "\n",
    "vectorizer_companies = CountVectorizer()\n",
    "vectorizer_companies.fit(all_companies)\n",
    "\n",
    "vectorizer_genres = CountVectorizer()\n",
    "vectorizer_genres.fit(all_genres)\n",
    "\n",
    "# Transformar datos de películas estrenadas\n",
    "actors_matrix = vectorizer_actors.transform(movies['actors'])\n",
    "directors_matrix = vectorizer_directors.transform(movies['directors_name'])\n",
    "companies_matrix = vectorizer_companies.transform(movies['production_companies'])\n",
    "genres_matrix = vectorizer_genres.transform(movies['genres'])\n",
    "\n",
    "# Transformar datos de futuras películas\n",
    "actors_matrix_futuras = vectorizer_actors.transform(futuras['actors'])\n",
    "directors_matrix_futuras = vectorizer_directors.transform(futuras['directors_name'])\n",
    "companies_matrix_futuras = vectorizer_companies.transform(futuras['production_companies'])\n",
    "genres_matrix_futuras = vectorizer_genres.transform(futuras['genres'])\n",
    "\n",
    "# Concatenar todas las características\n",
    "X = hstack([actors_matrix, directors_matrix, companies_matrix, genres_matrix])\n",
    "\n",
    "# Estandarizar características numéricas\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Guardar los vectorizadores y el escalador\n",
    "joblib.dump(vectorizer_actors, 'vectorizer_actors.pkl')\n",
    "joblib.dump(vectorizer_directors, 'vectorizer_directors.pkl')\n",
    "joblib.dump(vectorizer_companies, 'vectorizer_companies.pkl')\n",
    "joblib.dump(vectorizer_genres, 'vectorizer_genres.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Variable objetivo\n",
    "y = np.log1p(movies['revenue'])\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo KNeighborsRegressor con GridSearchCV\n",
    "param_grid = {'n_neighbors': [5, 10, 20, 50]}\n",
    "knn = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "print(f'Tiempo de entrenamiento (KNeighborsRegressor): {end_time - start_time} segundos')\n",
    "\n",
    "# Mejor modelo KNeighborsRegressor\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "joblib.dump(best_knn, 'revenue_predictor_knn.pkl')\n",
    "\n",
    "# Predecir y evaluar el modelo\n",
    "y_pred_log = best_knn.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)  # Transformación inversa del logaritmo\n",
    "y_test_original = np.expm1(y_test)  # Transformación inversa del logaritmo\n",
    "\n",
    "mse = mean_squared_error(y_test_original, y_pred)\n",
    "print(f'Error cuadrático medio (KNeighborsRegressor): {mse}')\n",
    "\n",
    "# Probar con GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=200, random_state=42)\n",
    "start_time = time.time()\n",
    "gbr.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "print(f'Tiempo de entrenamiento (GradientBoostingRegressor): {end_time - start_time} segundos')\n",
    "\n",
    "# Guardar el modelo GradientBoostingRegressor\n",
    "joblib.dump(gbr, 'revenue_predictor_gbr.pkl')\n",
    "\n",
    "# Predecir y evaluar el modelo\n",
    "y_pred_log_gbr = gbr.predict(X_test)\n",
    "y_pred_gbr = np.expm1(y_pred_log_gbr)  # Transformación inversa del logaritmo\n",
    "y_test_original = np.expm1(y_test)  # Transformación inversa del logaritmo\n",
    "\n",
    "mse_gbr = mean_squared_error(y_test_original, y_pred_gbr)\n",
    "print(f'Error cuadrático medio (GradientBoostingRegressor): {mse_gbr}')\n",
    "\n",
    "# Seleccionar las 10 películas con el revenue más alto del conjunto de prueba\n",
    "top_10_indices = y_test_original.nlargest(10).index\n",
    "top_10_movies = movies.loc[top_10_indices]\n",
    "top_10_real_revenue = y_test_original.loc[top_10_indices]\n",
    "top_10_predicted_revenue = pd.Series(y_pred_gbr, index=y_test.index).loc[top_10_indices]\n",
    "\n",
    "# Crear un DataFrame con los resultados y formatear los valores\n",
    "result_df = pd.DataFrame({\n",
    "    'title': top_10_movies['title'].values,\n",
    "    'real_revenue': top_10_real_revenue.apply(lambda x: f\"${x:,.0f}\"),\n",
    "    'predicted_revenue': top_10_predicted_revenue.apply(lambda x: f\"${x:,.0f}\")\n",
    "})\n",
    "\n",
    "print(result_df)\n",
    "\n",
    "# Ahora aplicamos el modelo sobre las futuras películas\n",
    "# Transformar y escalar las características usando los objetos cargados\n",
    "X_futuras = hstack([actors_matrix_futuras, directors_matrix_futuras, companies_matrix_futuras, genres_matrix_futuras])\n",
    "X_futuras = scaler.transform(X_futuras)\n",
    "\n",
    "# Predecir con el modelo entrenado (GradientBoostingRegressor en este caso)\n",
    "y_futuras_pred_log = gbr.predict(X_futuras)\n",
    "y_futuras_pred = np.expm1(y_futuras_pred_log)\n",
    "\n",
    "futuras['predicted_revenue'] = y_futuras_pred\n",
    "\n",
    "# Seleccionar las 10 películas con la predicción de revenue más alto\n",
    "top_10_futuras = futuras.nlargest(10, 'predicted_revenue').copy()\n",
    "\n",
    "# Formatear los valores de predicción de revenue\n",
    "top_10_futuras['predicted_revenue'] = top_10_futuras['predicted_revenue'].apply(lambda x: f\"${x:,.0f}\")\n",
    "\n",
    "print(top_10_futuras[['title', 'predicted_revenue']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
